name: Tests

on: workflow_dispatch

permissions:
  contents: read

env:
  PYTHONUTF8: 1
  LLM_MODEL_REPO: bartowski/Qwen_Qwen3-0.6B-GGUF
  LLM_MODEL_FILE: Qwen_Qwen3-0.6B-Q4_K_M.gguf
  
  LLM_MODEL_DIR: data/llm_model
  TTS_AUDIO_DIR: tests/test_files
  
  BOT_TOKEN: ${{ secrets.BOT_TOKEN }}
  ADMIN_CHAT_ID: ${{ secrets.ADMIN_CHAT_ID }}

jobs:
  download-models:
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true

      - name: Set up Python
        run: |
          uv python install 3.12
          uv venv

      - name: Install huggingface-hub
        run: uv pip install huggingface-hub[hf_xet]

      - name: Create model directory (need for Windows)
        run: mkdir -p ${{ env.LLM_MODEL_DIR }}

      - name: Download models
        run: |
          uv run hf download ${{ env.LLM_MODEL_REPO }} ${{ env.LLM_MODEL_FILE }} \
          --local-dir ${{ env.LLM_MODEL_DIR }}
          
      - name: Upload models artifact
        uses: actions/upload-artifact@v4
        with:
          name: models
          path: data
          overwrite: true

  test-linux:
    needs: download-models
    runs-on: ubuntu-24.04
    timeout-minutes: 60
    strategy:
      matrix:
        python-version: ["3.12"]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download models artifact
        uses: actions/download-artifact@v4
        with:
          name: models
          path: data
      
      - name: Check models exists
        run: |
          echo "LLM models:"
          ls -lh ${{ env.LLM_MODEL_DIR }}

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true

      - name: Set up Python
        run: |
          uv python install ${{ matrix.python-version }}
          uv venv
        
      - name: Install dependencies
        run: |
          uv pip install -r requirements.txt

      - name: Install ffmpeg
        run: sudo apt-get update && sudo apt-get install -y --no-install-recommends ffmpeg
  
      - name: Test with pytest
        env:
          LLAMA_ARG_MODEL: ${{ env.LLM_MODEL_DIR }}/${{ env.LLM_MODEL_FILE }}
        run: |
          uv run python -m pytest -vs

      - name: Upload TTS result artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: tts-audio-${{ matrix.python-version }}-${{ runner.os }}
          path: ${{ env.TTS_AUDIO_DIR }}
          if-no-files-found: ignore

  test-windows:
    needs: download-models
    runs-on: windows-2022
    timeout-minutes: 60
    strategy:
      matrix:
        python-version: ["3.12"]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download models artifact
        uses: actions/download-artifact@v4
        with:
          name: models
          path: data

      - name: Check model exists
        run: |
          echo "LLM models:"
          dir ${{ env.LLM_MODEL_DIR }}

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true

      - name: Set up Python
        run: |
          uv python install ${{ matrix.python-version }}
          uv venv

      - name: Install dependencies
        run: |
          uv pip install -r requirements.txt
          
      - name: Install ffmpeg
        run: choco install ffmpeg -y
        
      - name: Test with pytest
        env:
          LLAMA_ARG_MODEL: ${{ env.LLM_MODEL_DIR }}/${{ env.LLM_MODEL_FILE }}
        run: |
          uv run python -m pytest -vs

      - name: Upload TTS result artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: tts-audio-${{ matrix.python-version }}-${{ runner.os }}
          path: ${{ env.TTS_AUDIO_DIR }}
          if-no-files-found: ignore
          retention-days: 1
